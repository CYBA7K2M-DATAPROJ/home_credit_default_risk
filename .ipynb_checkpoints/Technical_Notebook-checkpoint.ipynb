{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:36:19.717059200Z",
     "start_time": "2024-06-19T21:36:19.687834700Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zip_directory(folder_path, zip_path):\n",
    "    \"\"\"\n",
    "    Zips the specified folder and saves it to the specified zip file path.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder to be zipped.\n",
    "        zip_path (str): The path where the zip file should be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the folder path exists\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"The folder path {folder_path} does not exist or is not a directory.\")\n",
    "\n",
    "    # Create a ZipFile object\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk through the directory\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create the full path to the file\n",
    "                full_path = os.path.join(root, file)\n",
    "                # Add file to the zip file\n",
    "                arcname = os.path.relpath(full_path, start=folder_path)\n",
    "                zipf.write(full_path, arcname=arcname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbea0ab7c5b237d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Compression of resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b95cc61b7ef1fbab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:38:12.922913900Z",
     "start_time": "2024-06-19T21:36:22.850771800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "zip_directory('./resources', './resources.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660498668ba91f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:45:16.594967800Z",
     "start_time": "2024-06-19T21:45:16.560643500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "zip_directory('./exports', './exports.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01f6838c64975a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:42:56.083375600Z",
     "start_time": "2024-06-19T21:42:53.035314800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement git (from versions: none)\n",
      "ERROR: No matching distribution found for git\n"
     ]
    }
   ],
   "source": [
    " pip install git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96edf4dcfc3291e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T21:42:41.674088300Z",
     "start_time": "2024-06-19T21:42:41.621346400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "\n",
    "def push_exports_to_github(repo_path, exports_folder, commit_message, branch='main'):\n",
    "    \"\"\"\n",
    "    Pushes the changes in the specified exports folder to GitHub.\n",
    "\n",
    "    Args:\n",
    "        repo_path (str): The path to the local git repository.\n",
    "        exports_folder (str): The path to the exports folder relative to the repository.\n",
    "        commit_message (str): The commit message for the changes.\n",
    "        branch (str): The branch to push the changes to. Default is 'main'.\n",
    "    \"\"\"\n",
    "    # Ensure the repository path exists\n",
    "    if not os.path.isdir(repo_path):\n",
    "        raise ValueError(f\"The repository path {repo_path} does not exist or is not a directory.\")\n",
    "\n",
    "    # Ensure the exports folder path exists\n",
    "    exports_path = os.path.join(repo_path, exports_folder)\n",
    "    if not os.path.isdir(exports_path):\n",
    "        raise ValueError(f\"The exports folder path {exports_path} does not exist or is not a directory.\")\n",
    "\n",
    "    try:\n",
    "        # Initialize the repository\n",
    "        repo = git.Repo(repo_path)\n",
    "\n",
    "        # Stage changes in the exports folder\n",
    "        repo.git.add(exports_path)\n",
    "\n",
    "        # Commit the changes\n",
    "        repo.index.commit(commit_message)\n",
    "\n",
    "        # Push the changes to the specified branch\n",
    "        origin = repo.remote(name='origin')\n",
    "        origin.push(refspec=f'{branch}:{branch}')\n",
    "\n",
    "        print(f\"Changes from '{exports_folder}' pushed to GitHub branch '{branch}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# Make sure your repo_path points to the local git repository\n",
    "repo_path = '/path/to/your/local/repo'\n",
    "exports_folder = 'exports'  # This should be the relative path from the repo root\n",
    "commit_message = 'Add files from exports directory'\n",
    "push_exports_to_github(repo_path, exports_folder, commit_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b6728b9bd3413",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Update Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57ab600557ff6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import check_call, CalledProcessError\n",
    "\n",
    "COMMIT_MESSAGE = \"Notebooks updates\"\n",
    "\n",
    "def git_add_commit_push():\n",
    "    try:\n",
    "        check_call([\"git\", \"add\", \".\"])\n",
    "        check_call([\"git\", \"commit\", \"-m\", COMMIT_MESSAGE])\n",
    "        check_call([\"git\", \"push\"])\n",
    "    except CalledProcessError as e:\n",
    "        print(f\"Error during git operations: {e}\")\n",
    "\n",
    "def main():\n",
    "    git_add_commit_push()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be65d1-3046-4ec1-beb3-6235b5ca77d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_call([\"git\", \"push\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b43f1db-4e6d-48ed-9d2b-e64a07dc64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def git_command(command):\n",
    "    try:\n",
    "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return result.stdout.decode(), result.stderr.decode()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return e.stdout.decode(), e.stderr.decode()\n",
    "\n",
    "def git_pull():\n",
    "    print(\"Stashing any local changes...\")\n",
    "    stdout, stderr = git_command([\"git\", \"stash\"])\n",
    "    if stderr:\n",
    "        print(f\"Error during git stash: {stderr}\")\n",
    "        return\n",
    "\n",
    "    print(\"Pulling latest changes from the repository...\")\n",
    "    stdout, stderr = git_command([\"git\", \"pull\"])\n",
    "    print(stdout)\n",
    "    if 'CONFLICT' in stdout or 'CONFLICT' in stderr:\n",
    "        print(\"Merge conflicts detected. Attempting to resolve automatically...\")\n",
    "        stdout, stderr = git_command([\"git\", \"merge\", \"--abort\"])\n",
    "        if stderr:\n",
    "            print(f\"Error during merge abort: {stderr}\")\n",
    "            return\n",
    "        stdout, stderr = git_command([\"git\", \"pull\", \"--strategy-option=theirs\"])\n",
    "        if stderr:\n",
    "            print(f\"Error during git pull with merge strategy: {stderr}\")\n",
    "            return\n",
    "\n",
    "    print(\"Applying stashed changes...\")\n",
    "    stdout, stderr = git_command([\"git\", \"stash\", \"pop\"])\n",
    "    if stderr:\n",
    "        print(f\"Error during git stash pop: {stderr}\")\n",
    "        return\n",
    "\n",
    "    print(\"Repository successfully updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7ab206-2fc3-4f46-bc22-d841a6482625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stashing any local changes...\n",
      "Pulling latest changes from the repository...\n",
      "Auto-merging Fusilier_Antoine_1_notebook_exploratory_analysis_and_cleaning_and_feature_enginering_022024.ipynb\n",
      "CONFLICT (content): Merge conflict in Fusilier_Antoine_1_notebook_exploratory_analysis_and_cleaning_and_feature_enginering_022024.ipynb\n",
      "Automatic merge failed; fix conflicts and then commit the result.\n",
      "\n",
      "Merge conflicts detected. Attempting to resolve automatically...\n",
      "Applying stashed changes...\n",
      "Error during git stash pop: No stash entries found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "git_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeb712-0d4c-4731-ac85-e482164558a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c33529-b206-48bc-aa2c-e0c8322c8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configurer Spark pour accéder à HDFS\n",
    "conf = SparkConf().setAppName(\"HDFS Access\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "# Exemple de lecture d'un fichier HDFS\n",
    "hdfs_url = \"hdfs://45.93.138.139:9000/path/to/your/file\"\n",
    "df = spark.read.text(hdfs_url)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb20e4d-4347-494a-a6c9-2b0bd72d1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
