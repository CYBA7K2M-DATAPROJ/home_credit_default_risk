{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import joblib\n",
    "import optuna\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports\n",
    "LOCAL_EXPORT_FOLDER_PATH='/content/exports'\n",
    "# Exports > Manual check path \n",
    "LOCAL_EXPORT_MANUAL_CHECK_PATCH_FOLDER_PATH=LOCAL_EXPORT_FOLDER_PATH+'/manual_check_patch'\n",
    "TARGET_COLUMNS=['TARGET',]\n",
    "LOCAL_EXPORT_MODELIZATION_FOLDER_PATH=LOCAL_EXPORT_FOLDER_PATH+'/modelization'\n",
    "MLFLOW_EXPERIMENT_NAME = 'generic_model_experiment'\n",
    "# Export > General Settings\n",
    "TESTING_MODE=True\n",
    "TESTING_MODE_MAX_LINES=1000\n",
    "TESTING_MODE_SUB_FOLDER_NAME='testing_data'\n",
    "GENERAL_CHUNK_SIZE=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B6QYxuCQVGP1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Liste des modèles et leurs hyperparamètres\u001b[39;00m\n\u001b[1;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mLogisticRegression\u001b[49m(),\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m7\u001b[39m),\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m         }\n\u001b[1;32m      9\u001b[0m     },\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestClassifier(),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m     15\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     17\u001b[0m         }\n\u001b[1;32m     18\u001b[0m     },\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradient Boosting\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: GradientBoostingClassifier(),\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[1;32m     26\u001b[0m         }\n\u001b[1;32m     27\u001b[0m     },\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     32\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.7\u001b[39m]\n\u001b[1;32m     35\u001b[0m         }\n\u001b[1;32m     36\u001b[0m     },\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLightGBM\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(),\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m62\u001b[39m, \u001b[38;5;241m127\u001b[39m],\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting_type\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdart\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     44\u001b[0m         }\n\u001b[1;32m     45\u001b[0m     },\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCatBoost\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: cb\u001b[38;5;241m.\u001b[39mCatBoostClassifier(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m     50\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_leaf_reg\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m     53\u001b[0m         }\n\u001b[1;32m     54\u001b[0m     },\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: SVC(probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m7\u001b[39m),\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdegree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     61\u001b[0m         }\n\u001b[1;32m     62\u001b[0m     },\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: KNeighborsClassifier(),\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanhattan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     69\u001b[0m         }\n\u001b[1;32m     70\u001b[0m     },\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeural Network\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: MLPClassifier(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m),\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layer_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m: [(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m100\u001b[39m,), (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m)],\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m]\n\u001b[1;32m     77\u001b[0m         }\n\u001b[1;32m     78\u001b[0m     }\n\u001b[1;32m     79\u001b[0m }\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Fonction d'optimisation des hyperparamètres avec Optuna\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial, X_train, y_train):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Liste des modèles et leurs hyperparamètres\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': np.logspace(-3, 3, 7),\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'subsample': [0.8, 0.9, 1.0]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'colsample_bytree': [0.3, 0.7]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': lgb.LGBMClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'num_leaves': [31, 62, 127],\n",
    "            'boosting_type': ['gbdt', 'dart']\n",
    "        }\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': cb.CatBoostClassifier(verbose=0),\n",
    "        'params': {\n",
    "            'iterations': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'depth': [3, 4, 5],\n",
    "            'l2_leaf_reg': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True),\n",
    "        'params': {\n",
    "            'C': np.logspace(-3, 3, 7),\n",
    "            'kernel': ['linear', 'rbf', 'poly'],\n",
    "            'degree': [3, 4, 5]\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [5, 10, 20],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan']\n",
    "        }\n",
    "    },\n",
    "    'Neural Network': {\n",
    "        'model': MLPClassifier(max_iter=500),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(50, 50), (100,), (100, 50)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'alpha': [0.0001, 0.001, 0.01]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fonction d'optimisation des hyperparamètres avec Optuna\n",
    "def objective(trial, X_train, y_train):\n",
    "    classifier_name = trial.suggest_categorical('classifier', list(models.keys()))\n",
    "    classifier_info = models[classifier_name]\n",
    "    classifier = classifier_info['model']\n",
    "    params = classifier_info['params']\n",
    "\n",
    "    trial_params = {}\n",
    "    for param, values in params.items():\n",
    "        if isinstance(values[0], (int, float)):\n",
    "            trial_params[param] = trial.suggest_float(param, min(values), max(values))\n",
    "        else:\n",
    "            trial_params[param] = trial.suggest_categorical(param, values)\n",
    "    \n",
    "    classifier.set_params(**trial_params)\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    score = cross_val_score(pipeline, X_train, y_train, n_jobs=-1, cv=5, scoring='accuracy', error_score='raise')\n",
    "    accuracy = score.mean()\n",
    "    return accuracy\n",
    "\n",
    "# Fonction pour ré-entraîner un modèle jusqu'à atteindre une amélioration significative\n",
    "def retrain_model(best_pipeline, X_train, y_train, X_test, y_test, threshold=0.01, max_iter=10):\n",
    "    previous_score = 0\n",
    "    for iteration in range(max_iter):\n",
    "        best_pipeline.fit(X_train, y_train)\n",
    "        y_pred = best_pipeline.predict(X_test)\n",
    "        current_score = accuracy_score(y_test, y_pred)\n",
    "        improvement = current_score - previous_score\n",
    "        if improvement < threshold:\n",
    "            break\n",
    "        previous_score = current_score\n",
    "        print(f\"Iteration {iteration + 1}, Accuracy: {current_score}, Improvement: {improvement}\")\n",
    "    return best_pipeline, current_score\n",
    "\n",
    "# Fonction de visualisation\n",
    "def plot_roc_curve(y_test, y_pred_proba, model_name, output_dir):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(output_dir, f'roc_curve_{model_name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, model_name, output_dir):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.savefig(os.path.join(output_dir, f'confusion_matrix_{model_name}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def plot_cross_val_scores(model_scores, model_names, output_dir):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x=model_names, y=model_scores)\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Cross-Validation Score')\n",
    "    plt.title('Model Comparison - Cross-Validation Scores')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(output_dir, 'cross_val_scores.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Méthode principale\n",
    "def train_and_evaluate_models(base_path, output_folder, target_columns, testing=False, chunk_size=1000, testing_sub_path_name='test'):\n",
    "    all_scores = {}\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.endswith('application_train.csv'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                test_file_path = file_path.replace('application_train.csv', 'application_test.csv')\n",
    "\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                # Lire les fichiers CSV\n",
    "                train_data = pd.read_csv(file_path)\n",
    "                test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "                for target_column in target_columns:\n",
    "                    print(f\"Using target column: {target_column}\")\n",
    "\n",
    "                    # Séparation des features et de la cible\n",
    "                    X_train = train_data.drop(target_column, axis=1)\n",
    "                    y_train = train_data[target_column]\n",
    "                    X_test = test_data.drop(target_column, axis=1)\n",
    "                    y_test = test_data[target_column]\n",
    "\n",
    "                    # Optimisation des hyperparamètres avec Optuna\n",
    "                    study = optuna.create_study(direction='maximize')\n",
    "                    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=100)\n",
    "\n",
    "                    print('Number of finished trials: ', len(study.trials))\n",
    "                    print('Best trial:')\n",
    "                    trial = study.best_trial\n",
    "\n",
    "                    print('  Value: ', trial.value)\n",
    "                    print('  Params: ')\n",
    "                    for key, value in trial.params.items():\n",
    "                        print('    {}: {}'.format(key, value))\n",
    "\n",
    "                    # Entraîner le meilleur modèle\n",
    "                    best_classifier_name = trial.params['classifier']\n",
    "                    best_classifier_info = models[best_classifier_name]\n",
    "                    best_classifier = best_classifier_info['model']\n",
    "                    best_params = {k: v for k, v in trial.params.items() if k != 'classifier'}\n",
    "\n",
    "                    best_classifier.set_params(**best_params)\n",
    "\n",
    "                    # Création du pipeline avec le meilleur modèle\n",
    "                    best_pipeline = Pipeline(steps=[\n",
    "                        ('classifier', best_classifier)\n",
    "                    ])\n",
    "\n",
    "                    best_pipeline, best_score = retrain_model(best_pipeline, X_train, y_train, X_test, y_test)\n",
    "\n",
    "                    # Stocker les scores de validation croisée\n",
    "                    all_scores[best_classifier_name] = study.trials_dataframe().value.values\n",
    "\n",
    "                    # Déterminer le chemin de sortie\n",
    "                    relative_path = os.path.relpath(root, base_path)\n",
    "                    if testing:\n",
    "                        output_dir = os.path.join(output_folder, testing_sub_path_name, relative_path, target_column)\n",
    "                    else:\n",
    "                        output_dir = os.path.join(output_folder, relative_path, target_column)\n",
    "                        \n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "\n",
    "                    model_path = os.path.join(output_dir, f'best_{best_classifier_name}_model.pkl')\n",
    "                    joblib.dump(best_pipeline, model_path)\n",
    "\n",
    "                    # Évaluation du modèle\n",
    "                    y_pred = best_pipeline.predict(X_test)\n",
    "                    y_pred_proba = best_pipeline.predict_proba(X_test)\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "                    print(f\"Accuracy: {accuracy}\")\n",
    "                    print(f\"ROC AUC: {roc_auc}\")\n",
    "                    print(confusion_matrix(y_test, y_pred))\n",
    "                    print(classification_report(y_test, y_pred))\n",
    "\n",
    "                    # Logging avec mlflow\n",
    "                    mlflow.set_experiment('credit_scoring')\n",
    "                    with mlflow.start_run():\n",
    "                        mlflow.log_params(trial.params)\n",
    "                        mlflow.log_metric('accuracy', accuracy)\n",
    "                        mlflow.log_metric('roc_auc', roc_auc)\n",
    "                        mlflow.sklearn.log_model(best_pipeline, 'model')\n",
    "                        mlflow.log_artifact(file_path)\n",
    "                        mlflow.log_artifact(test_file_path)\n",
    "\n",
    "                    print(f'Model saved at {model_path}')\n",
    "\n",
    "                    # Visualisation des résultats\n",
    "                    plot_roc_curve(y_test, y_pred_proba, best_classifier_name, output_dir)\n",
    "                    plot_confusion_matrix(y_test, y_pred, best_classifier_name, output_dir)\n",
    "\n",
    "    # Visualisation des scores de validation croisée\n",
    "    model_names = list(all_scores.keys())\n",
    "    model_scores = [score for scores in all_scores.values() for score in scores]\n",
    "    model_names_repeated = [model for model in model_names for _ in range(len(all_scores[model]))]\n",
    "\n",
    "    plot_cross_val_scores(model_scores, model_names_repeated, output_folder)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_models(\n",
    "    base_path=LOCAL_EXPORT_MANUAL_CHECK_PATCH_FOLDER_PATH, \n",
    "    output_folder=LOCAL_EXPORT_MODELIZATION_FOLDER_PATH, \n",
    "    target_columns=TARGET_COLUMNS, \n",
    "    testing=TESTING_MODE, \n",
    "    chunk_size=GENERAL_CHUNK_SIZE, \n",
    "    testing_sub_path_name=TESTING_MODE_SUB_FOLDER_NAME)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
